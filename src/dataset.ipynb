{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["asic imports"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os, glob, re, yaml, random, argparse\n", "from munch import DefaultMunch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from helpers import * # custom helpers functions"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ata processing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import librosa\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "from skimage.metrics import structural_similarity as ssim"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from alive_progress import alive_bar, alive_it, config_handler\n", "config_handler.set_global(theme='classic')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["config = DefaultMunch.fromDict(yaml.safe_load(open(\"config.yml\"))['dataset'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["arguments (for grid search)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = argparse.ArgumentParser()\n", "parser.add_argument('--length', dest='length', type=float)\n", "parser.add_argument('--mic', dest='mic', type=int)\n", "parser.add_argument('--min_duration', dest='min_duration', type=float)\n", "parser.add_argument('--n_triplets', dest='n_triplets', type=int)\n", "parser.add_argument('--sr', dest='sr', type=int)\n", "parser.add_argument('--mode', dest='mode')\n", "parser.add_argument('--n_mfcc', dest='n_mfcc', type=int)\n", "parser.add_argument('--n_mels', dest='n_mels', type=int)\n", "parser.add_argument('--n_fft', dest='n_fft', type=int)\n", "parser.add_argument('--fmin', dest='fmin', type=int)\n", "parser.add_argument('--fmax', dest='fmax', type=int)\n", "parser.add_argument('--power', dest='power', type=int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["args = parser.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def args_conf(name):\n", "    if(hasattr(args, name) and getattr(args, name) is not None):\n", "        return getattr(args, name)\n", "    return getattr(config, name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["extract features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_features(file_path, length=args_conf('length'), overlap=args_conf('overlap'), max_count=args_conf('max_count'), min_duration=args_conf('min_duration'), mode='spectogram'):\n", "    # length - in seconds to create audio cuts\n", "    # overlap - between audio cuts in percent, default no overlap\n", "    # max_count - max number of blocks per audio\n", "    y, sr = librosa.load(file_path, sr=args_conf('sr'), mono=True)\n", "    y, _ = librosa.effects.trim(y, top_db=args_conf('top_db'), ref=np.max)\n", "    duration = librosa.get_duration(y=y, sr=sr)\n", "    if(duration <= min_duration):\n", "        return [], None\n", "    buffer = size = int(length * sr)\n", "    samples_total = len(y)\n", "    samples_wrote = 0\n", "    count = 0\n", "    features = []\n", "    while (samples_wrote < samples_total and count < max_count):\n", "        #check if the buffer is not exceeding total samples\n", "        if buffer > samples_total - samples_wrote:\n", "            buffer = samples_total - samples_wrote\n", "        block = y[samples_wrote: (samples_wrote + buffer)]\n", "        block_duration = librosa.get_duration(y=block, sr=sr)\n", "        #print(f'full duration {round(duration, 2)}, block {count}, duration {round(block_duration, 2)}')\n", "        if(block_duration < min_duration):\n", "            break\n\n", "        # short blocks pad with zeros to fit size\n", "        block = librosa.util.fix_length(block, size=(size))\n", "        if args_conf('mode') == 'spectogram':\n", "            feature = librosa.feature.melspectrogram(y=block, sr=sr, n_mels=args_conf('n_mels'), n_fft=args_conf('n_fft'), fmin=args_conf('fmin'), fmax=args_conf('fmax'), power=args_conf('power'))\n", "        else:\n", "            feature = librosa.feature.mfcc(y=block, sr=sr, n_mfcc=args_conf('n_mfcc'), n_mels=args_conf('n_mels'), n_fft=args_conf('n_fft'), fmin=args_conf('fmin'), fmax=args_conf('fmax'), power=args_conf('power')) \n", "        features.append(feature)\n", "        \n", "        if buffer >= samples_total - samples_wrote:\n", "            samples_wrote += buffer\n", "        else:\n", "            samples_wrote += int(buffer * (1 - overlap))\n", "        count += 1\n", "    #print(f'+++ {len(features)} +++' if len(features) > 0 else '--------')\n", "    return features, duration"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create speakers dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_speakers_dict(directory, mic=1):\n", "    speaker_dict = {}\n", "   \n", "    for speaker_dir in sorted(glob.glob(os.path.join(directory, \"*/\"))):\n", "        speaker_id = int(re.search(r'\\d+',os.path.basename(os.path.dirname(speaker_dir))).group())\n", "        speaker_audio = glob.glob(os.path.join(speaker_dir, f\"*mic{mic}.flac\"))\n", "        speaker_dict[speaker_id] = []\n", "        for audio_path in speaker_audio:\n", "            speaker_dict[speaker_id].append(audio_path)\n", "                \n", "    return speaker_dict"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_data(dict, max_speakers, max_recordings, mode='mfcc'):\n", "    data, labels, duration = [], [], []\n", "    speakers = list(dict.keys())[:max_speakers]\n", "    speakers_len = len(speakers)\n", "    print(f'\\nProcessing recordings for {speakers_len} speakers ')\n", "    for id, speaker_id in enumerate(speakers):\n", "        recordings = dict[speaker_id][:max_recordings]\n", "        for recording in alive_it(recordings, title=f'Speaker {speaker_id} {id+1}/{speakers_len}'):\n", "            # multiple features per recording\n", "            features, d = extract_features(recording, mode=mode)\n", "            for feature in features:\n", "                duration.append(d)\n", "                data.append(feature)\n", "                labels.append(id)\n", "    return [np.array(data), np.array(labels), np.array(duration)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_feature(X, y, label):\n", "    idx = np.random.randint(len(y))\n", "    while y[idx] != label:\n", "        idx = np.random.randint(len(y))\n", "    return X[idx]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n def get_triplet(X, y):<br>\n", "    keys = list(set(y))<br>\n", "    key = random.choice(keys)<br>\n", "    indicies = list(np.where(y == key)[0])<br>\n", "    anch_i, pos_i = random.sample(indicies, 2)<br>\n", "    neg_key = random.choice([id for id in keys if id != key])<br>\n", "    neg_i = random.choice(list(np.where(y == neg_key)[0]))<br>\n", "    anch, pos, neg = X[anch_i], X[pos_i], X[neg_i]<br>\n", "    ap_ssim = ssim(anch, pos, data_range=pos.max() - pos.min())<br>\n", "    an_ssim = ssim(anch, neg, data_range=neg.max() - neg.min())<br>\n", "    print('AP: ',round(ap_ssim,3),'AN: ',round(an_ssim,3), 'DIFF: ', ap_ssim - an_ssim)<br>\n", "  return anch, pos, neg \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_triplet(X, y):\n", "    while True:\n", "        keys = list(set(y))\n", "        key = random.choice(keys)\n", "        indicies = list(np.where(y == key)[0])\n", "        anch_i, pos_i = random.sample(indicies, 2)\n", "        neg_key = random.choice([id for id in keys if id != key])\n", "        neg_i = random.choice(list(np.where(y == neg_key)[0]))\n", "        anch, pos, neg = X[anch_i], X[pos_i], X[neg_i]\n", "        return anch, pos, neg"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_triplets(X, y, n):\n", "    anchors, positives, negatives = [], [], []\n", "    labels = np.ones(n)\n", "    for i in range(n):\n", "        anchor, positive, negative = get_triplet(X, y)\n", "        anchors.append(anchor)\n", "        positives.append(positive)\n", "        negatives.append(negative)\n", "    \n", "    return [np.array(anchors), np.array(positives), np.array(negatives)], labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_triplets_unique(X, y, n):\n", "    triplets = set()\n", "    shape = None\n", "    print(f'\\nGenerating {n} unique triplets')\n", "    with alive_bar(n) as bar:\n", "        while(len(triplets) < n):\n", "            anchor, positive, negative = get_triplet(X, y)\n", "            if(shape == None):\n", "                shape = anchor.shape\n", "            triplet = (anchor.tobytes(), positive.tobytes(), negative.tobytes())\n", "            if(set_add(triplets, triplet)):\n", "                bar()\n", "    anchors = [np.frombuffer(triplet[0], dtype='float32').reshape(shape) for triplet in triplets]\n", "    positives = [np.frombuffer(triplet[1], dtype='float32').reshape(shape) for triplet in triplets]\n", "    negatives = [np.frombuffer(triplet[2], dtype='float32').reshape(shape) for triplet in triplets]\n", "    labels = np.ones(len(triplets))\n", "    \n", "    return [np.array(anchors), np.array(positives), np.array(negatives)], labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def print_audio_lengths(d):\n", "    print(f'\\nLength: {len(d)}, Mean: {np.mean(d)}, Median: {np.median(d)}, Max: {np.max(d)}, Min: {np.min(d)}')\n", "    print(f'unde 1s: {percent(len(np.where(d<=1)[0]), len(d))}, 1s - 2s: {percent(len(np.where((d >= 1) & (d <= 2))[0]), len(d))}')\n", "    print(f'2s - 3s: {percent(len(np.where((d >= 2) & (d <= 3))[0]), len(d))}, 3s - 4s: {percent(len(np.where((d >= 3) & (d <= 4))[0]), len(d))}')\n", "    print(f'4s - 5s: {percent(len(np.where((d >= 4) & (d <= 5))[0]), len(d))}, over 5s: {percent(len(np.where(d>=5)[0]), len(d))}\\n')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create dictionary from directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["speakers_dict = create_speakers_dict(config.directory, mic=args_conf('mic'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create dataset with extracted features and labels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y, d = create_data(speakers_dict, config.n_speakers, config.n_recordings, config.mode)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args_conf('test_size'), random_state=42)\n", "X_trip, y_trip = generate_triplets_unique(X_train, y_train, args_conf('n_triplets'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'\\nData shape: {X.shape}, Train Test split: {y_train.shape[0]} / {y_test.shape[0]}, Triplets shape: {X_trip[0].shape}\\n')\n", "#print_audio_lengths(d)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.savez('data/data.npz', X=X, y=y, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n", "np.savez('data/triplets.npz', X_trip=X_trip, y_trip=y_trip)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.save('data/settings.npy', {\n", "    'n_triplets':args_conf('n_triplets'),\n", "    'mode':args_conf('mode'),\n", "    'mic':args_conf('mic'),\n", "    'sr':args_conf('sr'),\n", "    'length':args_conf('length'),\n", "    'min_duration':args_conf('min_duration'),\n", "    'n_mfcc':args_conf('n_mfcc'),\n", "    'n_mels':args_conf('n_mels'),\n", "    'n_fft':args_conf('n_fft'),\n", "    'fmin':args_conf('fmin'),\n", "    'fmax':args_conf('fmax'),\n", "    'power':args_conf('power'),\n", "    }) "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}